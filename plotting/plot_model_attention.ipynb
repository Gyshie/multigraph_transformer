{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU config\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from dataloader.QuickdrawDataset4dict import *\n",
    "from dataloader.QuickdrawDataset4dict_2nn4nnjnn import *\n",
    "\n",
    "from utils.AverageMeter import AverageMeter\n",
    "from utils.accuracy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "num_workers = 16\n",
    "# exp = \"gt_2nn\"\n",
    "# epoch = 10\n",
    "\n",
    "# from network.graph_transformer import *\n",
    "# from network.graph_mlp import *\n",
    "# from network.graph_convnet import *\n",
    "# from network.graph_attention_net import *\n",
    "from network.final.graph_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('./dataloader/tiny_test_dataset_dict.pickle', 'rb'))\n",
    "dataset = QuickdrawDataset(\"/home/peng/dataset/tiny_quickdraw_coordinate/test/\", \"./dataloader/tiny_test_set.txt\", data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_configs=collections.OrderedDict()\n",
    "network_configs['output_dim']=345\n",
    "network_configs['n_heads']=8\n",
    "network_configs['embed_dim']=256\n",
    "network_configs['n_layers']=4\n",
    "network_configs['feed_forward_hidden']=4*network_configs['embed_dim']\n",
    "network_configs['normalization']='batch'\n",
    "network_configs['dropout']=0.1\n",
    "\n",
    "net = make_model(n_classes=345, coord_input_dim=2, feat_input_dim=2, feat_dict_size=103, \n",
    "                 n_layers=network_configs['n_layers'], n_heads=network_configs['n_heads'], \n",
    "                 embed_dim=network_configs['embed_dim'], feedforward_dim=network_configs['feed_forward_hidden'], \n",
    "                 normalization=network_configs['normalization'], dropout=network_configs['dropout'])\n",
    "net = net.cuda()\n",
    "# net.load_state_dict(torch.load(f\"./experimental_results/{exp}/checkpoints/{exp}_net_epoch{epoch}\")[\"network\"])\n",
    "net.load_state_dict(torch.load(\"final_checkpoint\")[\"network\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_function(dataloader):\n",
    "    validation_loss = AverageMeter()\n",
    "    validation_acc_1 = AverageMeter()\n",
    "    validation_acc_5 = AverageMeter()\n",
    "    validation_acc_10 = AverageMeter()\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (coordinate, label, flag_bits, stroke_len, attention_mask1, attention_mask2, attention_mask3, padding_mask, position_encoding) in enumerate(tqdm(dataloader, ascii=True)):\n",
    "            \n",
    "            coordinate = coordinate.cuda()\n",
    "            label = label.cuda()\n",
    "            flag_bits = flag_bits.cuda()\n",
    "            stroke_len = stroke_len.cuda()\n",
    "            attention_mask1 = attention_mask1.cuda()\n",
    "            attention_mask2 = attention_mask2.cuda()\n",
    "            attention_mask3 = attention_mask3.cuda()\n",
    "            padding_mask = padding_mask.cuda()\n",
    "            position_encoding = position_encoding.cuda()\n",
    "\n",
    "            # Resize inputs\n",
    "            flag_bits.squeeze_(2)\n",
    "            position_encoding.squeeze_(2)\n",
    "            stroke_len.unsqueeze_(1)\n",
    "            \n",
    "            output = net(coordinate, flag_bits, position_encoding, \n",
    "                         attention_mask1, attention_mask2, attention_mask3, \n",
    "                         padding_mask, stroke_len)\n",
    "\n",
    "            batch_loss = nn.CrossEntropyLoss()(output, label)\n",
    "\n",
    "            validation_loss.update(batch_loss.item(), coordinate.size(0))\n",
    "             \n",
    "            acc_1, acc_5, acc_10 = accuracy(output, label, topk = (1,5,10))\n",
    "            validation_acc_1.update(acc_1, coordinate.size(0))\n",
    "            validation_acc_5.update(acc_5, coordinate.size(0))\n",
    "            validation_acc_10.update(acc_10, coordinate.size(0))\n",
    "\n",
    "    print(\"loss: {}  acc@1:{}  acc@5:{}  acc@10:{}\".format(\n",
    "        validation_loss.avg, validation_acc_1.avg, validation_acc_5.avg, validation_acc_10.avg))\n",
    "\n",
    "    return validation_loss, validation_acc_1, validation_acc_5, validation_acc_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check for loading checkpoint: test accuracy should match reported performance\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# validate_function(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(p, coord, W, title=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        p: Matplotlib figure/subplot\n",
    "        coord: Coordinates of nodes\n",
    "        W: Adjacency matrix (where 0 -> connected; -1e10 -> not connected)\n",
    "        title: Title of figure/subplot\n",
    "    \n",
    "    Returns:\n",
    "        p: Updated figure/subplot\n",
    "    \"\"\"\n",
    "    \n",
    "    def _W_to_node_pairs(W):\n",
    "        \"\"\"Helper function to convert adjacency matrix into pairs of adjacent nodes\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        for r in range(len(W)):\n",
    "            for c in range(len(W)):\n",
    "                if W[r][c] == 0:\n",
    "                    pairs.append((r, c))\n",
    "        return pairs\n",
    "    \n",
    "    W_val = squareform(pdist(coord, metric='euclidean'))\n",
    "    G = nx.from_numpy_matrix(W_val)\n",
    "    pos = dict(zip(range(len(coord)), coord.tolist()))\n",
    "    edgelist = _W_to_node_pairs(W)\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, node_color='black', node_size=10)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist, alpha=1, width=1, edge_color='grey')\n",
    "    \n",
    "    if title is not None:\n",
    "        p.set_title(title)\n",
    "        \n",
    "    plt.gca().invert_yaxis()\n",
    "    return p\n",
    "\n",
    "def plot_heatmap(p, coord, W, W_pred, title=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        p: Matplotlib figure/subplot\n",
    "        coord: Coordinates of nodes\n",
    "        W: Adjacency matrix (where 0 -> connected; -1e10 -> not connected)\n",
    "        W_pred: Edge prediction/attention matrix\n",
    "        title: Title of figure/subplot\n",
    "    \n",
    "    Returns:\n",
    "        p: Updated figure/subplot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to symmetric matrix\n",
    "    W_pred = (W_pred + W_pred.T) * 0.5\n",
    "\n",
    "    def _W_pred_to_node_pairs(W, W_pred):\n",
    "        \"\"\"Helper function to convert edge predictions into pairs of adjacent nodes\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        edge_preds = []\n",
    "        for r in range(len(W_pred)):\n",
    "            for c in range(len(W_pred)):\n",
    "                if W[r][c] == 0:\n",
    "                    pairs.append((r, c))\n",
    "                    edge_preds.append(W_pred[r][c])\n",
    "        return pairs, edge_preds\n",
    "    \n",
    "    W_val = squareform(pdist(coord, metric='euclidean'))\n",
    "    G = nx.from_numpy_matrix(W_val)\n",
    "    pos = dict(zip(range(len(coord)), coord.tolist()))\n",
    "    edgelist, edgepred = _W_pred_to_node_pairs(W, W_pred)\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, node_color='black', node_size=10)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist, edge_color=edgepred, edge_cmap=plt.cm.Reds, width=1)\n",
    "    \n",
    "    if title is not None:\n",
    "        p.set_title(title)\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    return p\n",
    "\n",
    "def plot_heatmap_old(p, coord, W, W_pred, title=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        p: Matplotlib figure/subplot\n",
    "        coord: Coordinates of nodes\n",
    "        W: Adjacency matrix (where 0 -> connected; -1e10 -> not connected)\n",
    "        W_pred: Edge prediction/attention matrix\n",
    "        title: Title of figure/subplot\n",
    "    \n",
    "    Returns:\n",
    "        p: Updated figure/subplot\n",
    "    \"\"\"\n",
    "    \n",
    "    def _W_pred_to_node_pairs(W, W_pred):\n",
    "        \"\"\"Helper function to convert edge predictions into pairs of adjacent nodes\n",
    "        \"\"\"\n",
    "        pairs = []\n",
    "        edge_preds = []\n",
    "        for r in range(len(W_pred)):\n",
    "            for c in range(len(W_pred)):\n",
    "                if W[r][c] == 0:\n",
    "                    pairs.append((r, c))\n",
    "                    edge_preds.append(W_pred[r][c])\n",
    "        return pairs, edge_preds\n",
    "    \n",
    "    W_val = squareform(pdist(coord, metric='euclidean'))\n",
    "    G = nx.from_numpy_matrix(W_val)\n",
    "    pos = dict(zip(range(len(coord)), coord.tolist()))\n",
    "    edgelist, edgepred = _W_pred_to_node_pairs(W, W_pred)\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos, node_color='black', node_size=10)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist, edge_color=edgepred, edge_cmap=plt.cm.Reds, width=1)\n",
    "    \n",
    "    if title is not None:\n",
    "        p.set_title(title)\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually plot for individual array\n",
    "# name = 'cat_3'\n",
    "\n",
    "# def get_stroke_len(arr):\n",
    "#     for i in range(len(arr)-1,-1,-1):\n",
    "#         if ((arr[i] == np.array([0, 0, 0, 0])).all()):\n",
    "#             return i\n",
    "#     return 100\n",
    "\n",
    "# def get_flags(input_array):\n",
    "#     out_array = np.zeros([100, 1], int)\n",
    "#     assert input_array.shape == (100, 2)\n",
    "#     for idx, bits in enumerate(input_array):\n",
    "#         if ((bits == [1, 0]).all()):\n",
    "#             out_array[idx] = 100\n",
    "#         elif ((bits == [0, 1]).all()):\n",
    "#             out_array[idx] = 101\n",
    "#         else:\n",
    "#             out_array[idx] = 102\n",
    "#     return out_array\n",
    "\n",
    "# arr = np.load(f'images/load/{name}.npy')\n",
    "# stroke_len = get_stroke_len(arr)\n",
    "# coord = arr[:, :2]\n",
    "# flags = get_flags(arr[:, 2:])\n",
    "# Ws = [np.ones([100, 100], int)*-1e10,\n",
    "#      produce_adjacent_matrix_2_neighbors(flags, stroke_len), \n",
    "#      produce_adjacent_matrix_4_neighbors(flags, stroke_len),\n",
    "#      produce_adjacent_matrix_joint_neighbors(flags, stroke_len)]\n",
    "\n",
    "# f_idx = 0\n",
    "# f = plt.figure(f_idx, figsize=(len(Ws)*5, 5))\n",
    "# f.set_tight_layout(True)\n",
    "# for idx, mask in enumerate(Ws):\n",
    "#     ax = f.add_subplot(101 + len(Ws)*10 + idx)\n",
    "#     plot_graph(ax, \n",
    "#                coord=coord[:stroke_len], \n",
    "#                W=mask[:stroke_len, :stroke_len],\n",
    "#                title=f\"Graph {idx+1}\")\n",
    "# plt.savefig(f\"images/png/{name}-graphs.png\", format='png', dpi=600, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "# f_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (coordinate, label, flag_bits, stroke_len, attention_mask1, attention_mask2, attention_mask3, padding_mask, position_encoding) in enumerate(dataloader): \n",
    "        \n",
    "        if int(label) == 67:\n",
    "            \n",
    "            name = {\n",
    "                5: 'clock',\n",
    "                76: 'clock', \n",
    "                67: 'cat', \n",
    "                94: 'dog', \n",
    "                98: 'dragon',\n",
    "                26: 'bear',\n",
    "                307: 'teddy',\n",
    "                312: 'tiger',\n",
    "                34: 'bird'\n",
    "            }.get(int(label))\n",
    "\n",
    "            coordinate = coordinate.cuda()\n",
    "            label = label.cuda()\n",
    "            flag_bits = flag_bits.cuda()\n",
    "            stroke_len = stroke_len.cuda()\n",
    "            attention_mask1 = attention_mask1.cuda()\n",
    "            attention_mask2 = attention_mask2.cuda()\n",
    "            attention_mask3 = attention_mask3.cuda()\n",
    "            padding_mask = padding_mask.cuda()\n",
    "            position_encoding = position_encoding.cuda()\n",
    "\n",
    "            # Resize inputs\n",
    "            flag_bits.squeeze_(2)\n",
    "            position_encoding.squeeze_(2)\n",
    "            stroke_len.unsqueeze_(1)\n",
    "\n",
    "            output = net(coordinate, flag_bits, position_encoding, \n",
    "                         attention_mask1, attention_mask2, attention_mask3, \n",
    "                         padding_mask, stroke_len)\n",
    "            \n",
    "            acc_1, acc_5, acc_10 = accuracy(output, label, topk = (1,5,10))\n",
    "            print(f\"Groundtruth: {int(label)}, Prediction: {int(output.argmax())}\")\n",
    "            print(f\"Accuracy @1: {int(acc_1)}, @5: {int(acc_5)}, @10: {int(acc_10)}\")\n",
    "            \n",
    "            attention_1 = []\n",
    "            attention_2 = []\n",
    "            attention_3 = []\n",
    "            for layer in net.encoder.transformer_layers:\n",
    "                attention_1.append(layer.self_attention1.module.attn)\n",
    "                attention_2.append(layer.self_attention2.module.attn)\n",
    "                attention_3.append(layer.self_attention3.module.attn)\n",
    "\n",
    "            # Convert back to numpy format for plotting\n",
    "            coordinate = coordinate.cpu().numpy()\n",
    "            label = label.cpu().numpy()\n",
    "            flag_bits = flag_bits.cpu().numpy()\n",
    "            stroke_len = stroke_len.cpu().numpy()\n",
    "            attention_mask1 = attention_mask1.cpu().numpy()\n",
    "            attention_mask2 = attention_mask2.cpu().numpy()\n",
    "            attention_mask3 = attention_mask3.cpu().numpy()\n",
    "            padding_mask = padding_mask.cpu().numpy()\n",
    "            position_encoding = position_encoding.cpu().numpy()\n",
    "            \n",
    "            attention_1 = [attn.cpu().numpy() for attn in attention_1]\n",
    "            attention_2 = [attn.cpu().numpy() for attn in attention_2]\n",
    "            attention_3 = [attn.cpu().numpy() for attn in attention_3]\n",
    "            \n",
    "            stroke_len = int(stroke_len[0])\n",
    "            \n",
    "            f_idx = 0\n",
    "            f = plt.figure(f_idx, figsize=(3*5, 5))\n",
    "            f.set_tight_layout(True)\n",
    "            for idx, mask in enumerate([attention_mask1, attention_mask2, attention_mask3]):\n",
    "                ax = f.add_subplot(131 + idx)\n",
    "                plot_graph(ax, \n",
    "                           coord=coordinate[0][:stroke_len], \n",
    "                           W=mask[0][:stroke_len, :stroke_len],\n",
    "                           title=f\"Graph {idx+1}\")\n",
    "            plt.show()\n",
    "            f_idx += 1\n",
    "            \n",
    "            if input() == \"y\":\n",
    "\n",
    "                for idx, (mask, attention) in enumerate(zip([attention_mask1, attention_mask2, attention_mask3], [attention_1, attention_2, attention_3])):\n",
    "                    f = plt.figure(f_idx, figsize=(8*5, 4*5))\n",
    "                    f.set_tight_layout(True)\n",
    "                    subf_idx = 1\n",
    "                    \n",
    "                    print(f\"Graph {idx+1}\")\n",
    "                    for layer in range(network_configs['n_layers']):\n",
    "                        for head in range(network_configs['n_heads']):\n",
    "                            ax = f.add_subplot(4, 8, subf_idx)\n",
    "                            plot_heatmap_old(ax,\n",
    "                                         coord=coordinate[0][:stroke_len], \n",
    "                                         W=mask[0][:stroke_len, :stroke_len],\n",
    "                                         W_pred=attention[layer][head][0][:stroke_len, :stroke_len],\n",
    "                                         title=None)\n",
    "                            # \"Graph {idx+1}, Layer {layer+1}, Head {head+1}\"\n",
    "                            subf_idx += 1\n",
    "                    plt.savefig(f\"images/final/{name}-g{idx+1}-old.pdf\", format='pdf', dpi=1200, bbox_inches=\"tight\")\n",
    "                    plt.show()\n",
    "                f_idx += 1\n",
    "                \n",
    "                for idx, (mask, attention) in enumerate(zip([attention_mask1, attention_mask2, attention_mask3], [attention_1, attention_2, attention_3])):\n",
    "                    f = plt.figure(f_idx, figsize=(8*5, 4*5))\n",
    "                    f.set_tight_layout(True)\n",
    "                    subf_idx = 1\n",
    "                    \n",
    "                    print(f\"Graph {idx+1}\")\n",
    "                    for layer in range(network_configs['n_layers']):\n",
    "                        for head in range(network_configs['n_heads']):\n",
    "                            ax = f.add_subplot(4, 8, subf_idx)\n",
    "                            plot_heatmap(ax,\n",
    "                                         coord=coordinate[0][:stroke_len], \n",
    "                                         W=mask[0][:stroke_len, :stroke_len],\n",
    "                                         W_pred=attention[layer][head][0][:stroke_len, :stroke_len],\n",
    "                                         title=None)\n",
    "                            # \"Graph {idx+1}, Layer {layer+1}, Head {head+1}\"\n",
    "                            subf_idx += 1\n",
    "                    plt.savefig(f\"images/final/{name}-g{idx+1}-new.pdf\", format='pdf', dpi=1200, bbox_inches=\"tight\")\n",
    "                    plt.show()\n",
    "                f_idx += 1\n",
    "\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = {\n",
    "#     5: 'clock',\n",
    "#     76: 'clock', \n",
    "#     67: 'cat', \n",
    "#     94: 'dog', \n",
    "#     98: 'dragon2',\n",
    "#     26: 'bear',\n",
    "#     307: 'bear',\n",
    "#     312: 'tiger3',\n",
    "#     34: 'bird'\n",
    "# }.get(int(label))\n",
    "\n",
    "# # Saving figures      \n",
    "# f_idx = 0\n",
    "# f = plt.figure(f_idx, figsize=(3*5, 5))\n",
    "# f.set_tight_layout(True)\n",
    "# for idx, mask in enumerate([attention_mask1, attention_mask2, attention_mask3]):\n",
    "#     ax = f.add_subplot(131 + idx)\n",
    "#     plot_graph(ax, \n",
    "#                coord=coordinate[0][:stroke_len], \n",
    "#                W=mask[0][:stroke_len, :stroke_len],\n",
    "#                title=f\"Graph {idx+1}\")\n",
    "# plt.savefig(f\"images/{name}-graphs.pdf\", format='pdf', dpi=1200, bbox_inches=\"tight\")\n",
    "# plt.savefig(f\"images/png/{name}-graphs.png\", format='png', dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "# f_idx += 1\n",
    "\n",
    "\n",
    "# # f = plt.figure(f_idx, figsize=(8*5, 4*3*5))\n",
    "# # f.set_tight_layout(True)\n",
    "# # subf_idx = 1\n",
    "# # for idx, (mask, attention) in enumerate(zip([attention_mask1, attention_mask2, attention_mask3], [attention_1, attention_2, attention_3])):\n",
    "# #     for layer in range(network_configs['n_layers']):\n",
    "# #         for head in range(network_configs['n_heads']):\n",
    "# #             ax = f.add_subplot(12, 8, subf_idx)\n",
    "# #             plot_heatmap(ax,\n",
    "# #                          coord=coordinate[0][:stroke_len], \n",
    "# #                          W=mask[0][:stroke_len, :stroke_len],\n",
    "# #                          W_pred=attention[layer][head][0][:stroke_len, :stroke_len],\n",
    "# #                          title=f\"Graph {idx+1}, Layer {layer+1}, Head {head+1}\")\n",
    "# #             subf_idx += 1\n",
    "# # plt.savefig(f\"images/{name}_vert.pdf\", format='pdf', dpi=1200, bbox_inches=\"tight\")\n",
    "# # plt.savefig(f\"images/png/{name}_vert.png\", format='png', dpi=300, bbox_inches=\"tight\")\n",
    "# # plt.show()\n",
    "# # f_idx += 1\n",
    "\n",
    "\n",
    "# f = plt.figure(f_idx, figsize=(3*4*5, 8*5))\n",
    "# f.set_tight_layout(True)\n",
    "# subf_idx = 1\n",
    "\n",
    "# for head in range(network_configs['n_heads']):\n",
    "#     for idx, (mask, attention) in enumerate(zip([attention_mask1, attention_mask2, attention_mask3], [attention_1, attention_2, attention_3])):\n",
    "#         for layer in range(network_configs['n_layers']):\n",
    "#             ax = f.add_subplot(8, 12, subf_idx)\n",
    "#             plot_heatmap(ax,\n",
    "#                          coord=coordinate[0][:stroke_len], \n",
    "#                          W=mask[0][:stroke_len, :stroke_len],\n",
    "#                          W_pred=attention[layer][head][0][:stroke_len, :stroke_len],\n",
    "#                          title=f\"Graph {idx+1}, Layer {layer+1}, Head {head+1}\")\n",
    "#             subf_idx += 1\n",
    "# plt.savefig(f\"images/{name}_horz.pdf\", format='pdf', dpi=1200, bbox_inches=\"tight\")\n",
    "# plt.savefig(f\"images/png/{name}_horz.png\", format='png', dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "# f_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make GIFs\n",
    "# def update(layer):\n",
    "#     subf_idx = 1\n",
    "#     for idx, (mask, attention) in enumerate(zip([attention_mask1, attention_mask2, attention_mask3], [attention_1, attention_2, attention_3])):\n",
    "    \n",
    "#         for head in range(network_configs['n_heads']):\n",
    "#             ax = f.add_subplot(3, 8, subf_idx)\n",
    "#             plot_heatmap(ax,\n",
    "#                          coord=coordinate[0][:stroke_len], \n",
    "#                          W=mask[0][:stroke_len, :stroke_len],\n",
    "#                          W_pred=attention[layer][head][0][:stroke_len, :stroke_len],\n",
    "#                          title=f\"Mask {idx+1}, Layer {layer+1}, Head {head+1}\")\n",
    "#             subf_idx += 1\n",
    "            \n",
    "# f = plt.figure(0, figsize=(8*5, 3*5))\n",
    "# f.set_tight_layout(True)\n",
    "# anim = FuncAnimation(f, update, frames=np.arange(0, network_configs['n_layers']), interval=1000)\n",
    "# anim.save(f'images/gif/{name}.gif', dpi=300, writer='imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
